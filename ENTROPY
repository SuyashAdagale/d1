clc;
clear all;
close all;

%  INPUT SECTION  %
disp('Enter source probabilities:');
for i = 1:2
    px(i) = input(['Enter P(x' num2str(i) ') = ']);
end

disp('Enter conditional probabilities P(y|x):');
for i = 1:2
    for j = 1:2
        pygx(i,j) = input(['Enter P(y' num2str(j) '|x' num2str(i) ') = ']);
    end
end

%  COMPUTE P(y) %
py = zeros(1,2);
for j = 1:2
    for i = 1:2
        py(j) = py(j) + px(i) * pygx(i,j);
    end
end

%  ENTROPY H(X)  %
hx = 0;
for i = 1:2
    if px(i) > 0
        hx = hx + px(i) * log2(1/px(i));
    end
end

%  ENTROPY H(Y) %
hy = 0;
for j = 1:2
    if py(j) > 0
        hy = hy + py(j) * log2(1/py(j));
    end
end

% JOINT PROBABILITY P(x,y)  %
for i = 1:2
    for j = 1:2
        pxy(i,j) = px(i) * pygx(i,j);
    end
end

%  CONDITIONAL ENTROPY H(Y|X) %
Hygx = 0;
for i = 1:2
    for j = 1:2
        if pygx(i,j) > 0
            Hygx = Hygx + pxy(i,j) * log2(1/pygx(i,j));
        end
    end
end

%  JOINT ENTROPY H(X,Y)  %
Hxy = hx + Hygx;

%  MUTUAL INFORMATION I(X;Y)  %
Ixy = hy - Hygx;

%  DISPLAY RESULTS  %
disp('----------------------');
disp('P(x) = '); disp(px);
disp('P(y|x) = '); disp(pygx);
disp('P(y) = '); disp(py);
disp(['H(X)  = ' num2str(hx)]);
disp(['H(Y)  = ' num2str(hy)]);
disp('P(x,y) = '); disp(pxy);
disp(['H(Y|X) = ' num2str(Hygx)]);
disp(['H(X,Y) = ' num2str(Hxy)]);
disp(['I(X;Y) = ' num2str(Ixy)]);

%  ENTROPY VS PROBABILITY GRAPH  %
px_vals = 0:0.01:1;
Hx = -px_vals .* log2(px_vals) - (1 - px_vals) .* log2(1 - px_vals);
Hx(isnan(Hx)) = 0; % Handle log(0)
figure;
plot(px_vals, Hx, 'LineWidth', 1.5);
grid on;
xlabel('Probability p(x)');
ylabel('Entropy H(x)');
title('Entropy H(X) vs Probability p(x)');


%Output Values:-
%Enter P(xi) = 0.5
%Enter P(xi) = 0.5
%Enter P(yj/xi) = 0.6
%Enter P(yj/xi) = 0.4
%Enter P(yj/xi) = 0.4
%Enter P(yj/xi) = 0.6
%
%
%
